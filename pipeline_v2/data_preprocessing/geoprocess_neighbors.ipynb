{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Upstream and Downstream TMC Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_attr = pd.read_csv(\"../../data/shapefiles/tmc_attr.csv\")\n",
    "tmc_attr = tmc_attr.rename(columns={\"Tmc\": \"id_tmc\", \"Miles\":\"miles_tmc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmc_miles = tmc_attr[[\"id_tmc\", \"miles_tmc\"]]\n",
    "miles_tmc = (df_tmc_miles.set_index(\"id_tmc\")).to_dict(\"index\")\n",
    "with open(\"../../data/tmc_miles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(miles_tmc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shp(path):\n",
    "    net = nx.read_shp(path, simplify=True)\n",
    "    return net\n",
    "\n",
    "def build_tmc_dict(net):\n",
    "    tmc2edge = { }\n",
    "    for key in net.edges:\n",
    "        tmc_id = net.edges[key]['id']\n",
    "        if tmc_id not in tmc2edge:\n",
    "            tmc2edge[tmc_id] = [ ]\n",
    "        tmc2edge[tmc_id].append(key)\n",
    "    return tmc2edge\n",
    "\n",
    "def get_upstream_tmc(tmc2edge, tmc_id, miles_tmc, net, n=1, d=5):\n",
    "    out = set()    \n",
    "    for (end_node, bgn_node) in tmc2edge[tmc_id]:\n",
    "        dist = d\n",
    "        for e in nx.bfs_edges(net, bgn_node ,depth_limit=n):\n",
    "            prev_tmc = net.edges[e]['id']\n",
    "\n",
    "            # avoid repeating segments or tmc_id itself\n",
    "            if prev_tmc == tmc_id or prev_tmc in out:\n",
    "                continue\n",
    "            else:\n",
    "                out.add(prev_tmc)\n",
    "\n",
    "                # compute the range of nxt_tmc segment\n",
    "                if prev_tmc in miles_tmc:\n",
    "                    d = miles_tmc[prev_tmc][\"miles_tmc\"]\n",
    "                else:\n",
    "                    # if there's no record of range of prev_tmc, then compute the distance from the beginning point to the end point of prev_tmc\n",
    "                    d = 0\n",
    "                    for end, begin in tmc2edge[prev_tmc]:\n",
    "                        temp = ((begin[0]-end[0])**2 + (begin[1]-end[1])**2)**(0.5)\n",
    "                        d += temp\n",
    "                    d /= len(tmc2edge[tmc_id])\n",
    "                dist -= d\n",
    "\n",
    "            if dist <= 0:\n",
    "                break    \n",
    "    return list(out)\n",
    "\n",
    "def get_downstream_tmc(tmc2edge, tmc_id, miles_tmc, net, n=1, d=5):\n",
    "    out = set()    \n",
    "    for (end_node, bgn_node) in tmc2edge[tmc_id]:\n",
    "        dist = d\n",
    "        for e in nx.bfs_edges(net, end_node ,depth_limit=n, reverse=True):\n",
    "            # reverve back due to reverse of graph in bfs\n",
    "            r_e = (e[1],e[0])\n",
    "            nxt_tmc = net.edges[r_e]['id']\n",
    "            \n",
    "            # avoid repeating segments or tmc_id itself\n",
    "            if nxt_tmc == tmc_id or nxt_tmc in out:\n",
    "                continue\n",
    "            else:\n",
    "                out.add(nxt_tmc)\n",
    "\n",
    "                # compute the range of nxt_tmc segment\n",
    "                if nxt_tmc in miles_tmc:\n",
    "                    d = miles_tmc[nxt_tmc][\"miles_tmc\"]\n",
    "                else:\n",
    "                    d = 0\n",
    "                    for end, begin in tmc2edge[nxt_tmc]:\n",
    "                        temp = ((begin[0]-end[0])**2 + (begin[1]-end[1])**2)**(0.5)\n",
    "                        d += temp\n",
    "                    d /= len(tmc2edge[tmc_id])\n",
    "                dist -= d\n",
    "\n",
    "            if dist <= 0:\n",
    "                break    \n",
    "    return list(out)\n",
    "\n",
    "def get_neighbor_tmc(tmc_id, net, n=5):\n",
    "    tmc2edge = build_tmc_dict(net)\n",
    "    up = get_upstream_tmc(tmc2edge, tmc_id, net, n)\n",
    "    dn = get_downstream_tmc(tmc2edge, tmc_id, net, n)\n",
    "    return np.concatenate((up, dn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y2/1kk0np3x01qchz21plxx_m0w0000gn/T/ipykernel_34983/706437336.py:2: DeprecationWarning: read_shp is deprecated and will be removed in 3.0.See https://networkx.org/documentation/latest/auto_examples/index.html#geospatial.\n",
      "  net = nx.read_shp(path, simplify=True)\n"
     ]
    }
   ],
   "source": [
    "# be careful about the pwd\n",
    "# if there is an error with osgeo or gdal, try cd to Traffic-Prediction % cd pipeline_v2/data_preprocessing\n",
    "# this is because I installed gdal using pip inside Traffic-Prediction % cd pipeline_v2/data_preprocessing\n",
    "net = read_shp('../../data/shapefiles/tmc_shape_cranberry/cranberry.shp')\n",
    "tmc2edge = build_tmc_dict(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:00<00:00, 132292.56it/s]\n"
     ]
    }
   ],
   "source": [
    "prev_tmc = {}\n",
    "next_tmc = {}\n",
    "for tmc in tqdm(tmc2edge):\n",
    "    prev_tmc[tmc] = get_upstream_tmc(tmc2edge, tmc, miles_tmc, net, n=1, d=5)\n",
    "    next_tmc[tmc] = get_downstream_tmc(tmc2edge, tmc, miles_tmc, net, n=1, d=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/next_tmc_5_miles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(next_tmc, f)\n",
    "\n",
    "with open(\"../../data/prev_tmc_5_miles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(prev_tmc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Upsteam and Downstream XD Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xd_attr = pd.read_csv(\"./data/shapefiles/xd_attr.csv\")\n",
    "# xd_attr.XDSegID = xd_attr.XDSegID.apply(int).apply(str)\n",
    "# xd_attr.PreviousXD = xd_attr.PreviousXD.apply(lambda x: str(int(x)) if not np.isnan(x) else x)\n",
    "# xd_attr.NextXDSegI = xd_attr.NextXDSegI.apply(lambda x: str(int(x)) if not np.isnan(x) else x)\n",
    "# xd_attr = xd_attr.rename(columns={\"XDSegID\":\"id_xd\", \"PreviousXD\":\"id_xd_prev\", \"NextXDSegI\":\"id_xd_next\", \"Miles\":\"miles_xd\"})\n",
    "# xd_attr.to_csv(\"./data/shapefiles/xd_attr.csv\", index=False)\n",
    "\n",
    "# core_xd_attr = xd_attr.loc[:,[\"id_xd\", \"id_xd_prev\", \"id_xd_next\", \"miles_xd\"]]\n",
    "# core_xd_attr = core_xd_attr.set_index(keys=\"id_xd\")\n",
    "# core_xd_attr.to_csv(\"./data/shapefiles/core_xd_attr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_xd_attr = pd.read_csv(\"../../data/shapefiles/core_xd_attr.csv\")\n",
    "core_xd_attr = core_xd_attr.set_index(keys=\"id_xd\")\n",
    "dict_xd_attr = core_xd_attr.to_dict(orient=\"index\")  # key: <id_xd>; value: dict() with keys: 'id_xd_prev', 'id_xd_next', 'miles_xd'\n",
    "next_xd = {}\n",
    "prev_xd = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117679/117679 [00:01<00:00, 105897.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for xd in tqdm(dict_xd_attr):\n",
    "    next_dist = 5 # 5 miles\n",
    "    prev_dist = 5 # 5 miles\n",
    "    curr = xd\n",
    "    next = dict_xd_attr[curr]['id_xd_next']\n",
    "    prev = dict_xd_attr[curr]['id_xd_prev']\n",
    "\n",
    "    next_list = []\n",
    "    prev_list = []\n",
    "\n",
    "    # find next XD segments within 5 miles\n",
    "    while next_dist >= 0 and str(next) != \"nan\":\n",
    "        next_list.append(next)\n",
    "        if next not in dict_xd_attr:\n",
    "            break\n",
    "        else:\n",
    "            next_dist -= dict_xd_attr[next][\"miles_xd\"]\n",
    "            next = dict_xd_attr[next]['id_xd_next']\n",
    "    next_xd[xd] = next_list\n",
    "\n",
    "    # find previous XD segments within 5 miles\n",
    "    while prev_dist >= 0 and str(prev) != \"nan\":\n",
    "        prev_list.append(prev)\n",
    "        if prev not in dict_xd_attr:\n",
    "            break\n",
    "        else:\n",
    "            prev_dist -= dict_xd_attr[prev][\"miles_xd\"]\n",
    "            prev = dict_xd_attr[prev]['id_xd_next']\n",
    "    prev_xd[xd] = prev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/next_xd_5_miles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(next_xd, f)\n",
    "\n",
    "with open(\"../../data/prev_xd_5_miles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(prev_xd, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('traffic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c7976fd35f11d6b5acd37b5df05c2b1d9460872f4ccb0abe3e95e9a1eb343e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
