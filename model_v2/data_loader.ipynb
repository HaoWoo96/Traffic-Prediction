{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves to generate the datasets for training, validation and testing, which will be used for training baseline models.\n",
    "\n",
    "It follows the exact procedure and seed as the way those deep learning models are trained with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haowu/opt/anaconda3/envs/traffic/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "from utils import seed_torch, seed_worker\n",
    "from train import create_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = create_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful to use parser.parse_args([]) instead of parser.parse_args(). Otherwise it will prompt error. \n",
    "# The issue lies in JupyterNotebook\n",
    "# See answer in https://stackoverflow.com/questions/50360012/python-argparse-error-error-argument-count-invalid-int-value for more details\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "seed_torch(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficData(Dataset):\n",
    "    \"\"\"\n",
    "    Load data under folders\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.args = args  \n",
    "        \n",
    "        X_path = f\"{self.args.data_dir}/np_in_5min.npy\"  # sequence features of TMC segments in frequency of 5 min\n",
    "        Y_path = f\"{self.args.data_dir}/np_out_5min.npy\"  # ground truth of TMC speed & incident data in frequency of 5 min\n",
    "\n",
    "        self.X = torch.from_numpy(np.load(X_path)).float()  # (21060, feat_dim)\n",
    "\n",
    "        # (21060, num_seg, 4) the last dimension refers to 1. speed of all vehicles, 2. speed of truck, 3. speed of personal vehicles, 4. incident status\n",
    "        self.Y = torch.from_numpy(np.load(Y_path)).float()  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.size(0) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_idx_base = idx // 180\n",
    "        x_idx_remain = min(max(idx % 180, 6, self.args.seq_len_in-1), np.floor(186 - self.args.seq_len_out)) # ensure we have valid idx based on input and output sequence length\n",
    "        idx = int(x_idx_remain + x_idx_base * 180)\n",
    "        Y_idx = [idx-6 + i for i in range(self.args.seq_len_out+1)]  # be careful, the starting point (first idx) of Y is the same as the last idx of X, and won't count into output sequence length\n",
    "        \n",
    "        X = self.X[(idx-self.args.seq_len_in+1):idx+1, :]\n",
    "        Y = self.Y[Y_idx, :, :]\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "def get_dataset(args):\n",
    "    \"\"\"\n",
    "    Creates training, validation and testing data loaders for model training\n",
    "    \"\"\"\n",
    "    whole_dataset = TrafficData(args=args)\n",
    "\n",
    "    # train_size = int(np.ceil(args.data_train_ratio * len(whole_dataset)))\n",
    "    # test_size = len(whole_dataset) - train_size\n",
    "\n",
    "    # make sure the splitting preserves the integrity of 180 slots in a day\n",
    "    train_size = int(np.ceil(args.data_train_ratio * (len(whole_dataset)/180))) * 180   # 14760\n",
    "    val_size = int(np.ceil(args.data_val_ratio * (len(whole_dataset)/180))) * 180   # 4320\n",
    "    test_size = len(whole_dataset) - train_size - val_size   # 1980\n",
    "\n",
    "    # split train and test dataset\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(args.seed)\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset = whole_dataset, lengths = [train_size, val_size, test_size], generator=g)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = get_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_train_in_5min = np.array([i[0].detach().numpy() for i in train_dataset])\n",
    "np_train_out_5min = np.array([i[1].detach().numpy() for i in train_dataset])\n",
    "np_val_in_5min = np.array([i[0].detach().numpy() for i in val_dataset])\n",
    "np_val_out_5min = np.array([i[1].detach().numpy() for i in val_dataset])\n",
    "np_test_in_5min = np.array([i[0].detach().numpy() for i in test_dataset])\n",
    "np_test_out_5min = np.array([i[1].detach().numpy() for i in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{args.data_dir}/np_train_in_5min.npy\", np_train_in_5min)\n",
    "np.save(f\"{args.data_dir}/np_train_out_5min.npy\", np_train_out_5min)\n",
    "np.save(f\"{args.data_dir}/np_val_in_5min.npy\", np_val_in_5min)\n",
    "np.save(f\"{args.data_dir}/np_val_out_5min.npy\", np_val_out_5min)\n",
    "np.save(f\"{args.data_dir}/np_test_in_5min.npy\", np_test_in_5min)\n",
    "np.save(f\"{args.data_dir}/np_test_out_5min.npy\", np_test_out_5min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('traffic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c7976fd35f11d6b5acd37b5df05c2b1d9460872f4ccb0abe3e95e9a1eb343e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
